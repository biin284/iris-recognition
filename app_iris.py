import streamlit as st
import cv2
import torch
import numpy as np
import segmentation_models_pytorch as smp
from torchvision import models, transforms
from PIL import Image
import torch.nn.functional as F
import os

# --- 1. C·∫§U H√åNH ---
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
UNET_PATH = 'iris_unet_v3.pth'
ARCFACE_PATH = 'iris_arcface_best.pth'
IDS_DIR = 'identities'  # Th∆∞ m·ª•c ch·ª©a d·ªØ li·ªáu ƒë·ªãnh danh
THRESHOLD = 0.222  # Ng∆∞·ª°ng an to√†n
MIN_IRIS_RATIO = 0.020
MIN_CIRCULARITY = 0.40

arc_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])


# --- 2. LOAD M√î H√åNH ---
class IrisArcFace(torch.nn.Module):
    def __init__(self):
        super().__init__()
        self.backbone = models.mobilenet_v3_large(weights=None)
        self.backbone.classifier = torch.nn.Sequential(
            torch.nn.Linear(960, 512),
            torch.nn.BatchNorm1d(512)
        )

    def forward(self, x): return self.backbone(x)


@st.cache_resource
def init_system():
    # Load U-Net
    unet = smp.Unet(encoder_name="efficientnet-b0", in_channels=3, classes=1, activation=None).to(DEVICE)
    if os.path.exists(UNET_PATH):
        unet.load_state_dict(torch.load(UNET_PATH, map_location=DEVICE))

    # Load ArcFace
    arcface = IrisArcFace().to(DEVICE)
    if os.path.exists(ARCFACE_PATH):
        sd = torch.load(ARCFACE_PATH, map_location=DEVICE)
        arcface.load_state_dict({k: v for k, v in sd.items() if 'head' not in k}, strict=False)

    unet.eval()
    arcface.eval()
    return unet, arcface


# --- 3. C√ÅC H√ÄM X·ª¨ L√ù D·ªÆ LI·ªÜU ---

def load_identity_db():
    """T·∫£i to√†n b·ªô d·ªØ li·ªáu ng∆∞·ªùi d√πng t·ª´ th∆∞ m·ª•c identities"""
    db = {}
    if not os.path.exists(IDS_DIR):
        os.makedirs(IDS_DIR)
        return db

    for f in os.listdir(IDS_DIR):
        if f.endswith('.pt'):
            # T√™n file d·∫°ng "long_identity.pt" -> L·∫•y t√™n "Long"
            name = f.replace("_identity.pt", "").capitalize()
            path = os.path.join(IDS_DIR, f)
            try:
                embedding = torch.load(path, map_location=DEVICE)
                db[name] = embedding
            except Exception as e:
                st.error(f"L·ªói t·∫£i file {f}: {e}")
    return db


def save_embedding(name, embedding):
    """L∆∞u ho·∫∑c c·∫≠p nh·∫≠t vector ƒë·∫∑c tr∆∞ng c·ªßa ng∆∞·ªùi d√πng"""
    if not os.path.exists(IDS_DIR):
        os.makedirs(IDS_DIR)

    # Chu·∫©n h√≥a t√™n file (ch·ªØ th∆∞·ªùng, kh√¥ng d·∫•u c√°ch)
    safe_name = name.lower().strip().replace(" ", "_")
    filename = f"{safe_name}_identity.pt"
    save_path = os.path.join(IDS_DIR, filename)

    # N·∫øu ƒë√£ c√≥ file c≈© -> C·ªông trung b√¨nh ƒë·ªÉ c·∫≠p nh·∫≠t (H·ªçc tƒÉng c∆∞·ªùng)
    if os.path.exists(save_path):
        old_emb = torch.load(save_path, map_location=DEVICE)
        new_emb = (old_emb + embedding) / 2.0
        new_emb = F.normalize(new_emb, p=2, dim=1)  # Chu·∫©n h√≥a l·∫°i sau khi c·ªông
    else:
        new_emb = embedding

    torch.save(new_emb, save_path)
    return True


def extract_v4(frame, unet, arcface):
    """Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng m·ªëng m·∫Øt t·ª´ ·∫£nh"""
    h, w = frame.shape[:2]
    roi_area = h * w
    img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    img_input = cv2.resize(img_rgb, (256, 256))
    img_input = img_input.transpose(2, 0, 1).astype(np.float32) / 255.0
    img_tensor = torch.tensor(img_input).unsqueeze(0).to(DEVICE)

    with torch.no_grad():
        mask = (torch.sigmoid(unet(img_tensor)).cpu().numpy()[0, 0] > 0.5).astype(np.uint8) * 255
    mask = cv2.resize(mask, (w, h))

    # T√¨m v√πng m·ªëng m·∫Øt
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    best_cnt, max_area = None, 0

    for cnt in contours:
        area = cv2.contourArea(cnt)
        perimeter = cv2.arcLength(cnt, True)
        if perimeter == 0: continue
        circularity = 4 * np.pi * (area / (perimeter ** 2))

        # L·ªçc nhi·ªÖu
        if circularity > MIN_CIRCULARITY and area > max_area:
            max_area, best_cnt = area, cnt

    if best_cnt is None: return None, 0, "KH√îNG T√åM TH·∫§Y M·∫ÆT", None

    # C·∫Øt v√† TƒÉng c∆∞·ªùng ·∫£nh
    masked = cv2.bitwise_and(frame, frame, mask=mask)
    l, a, b = cv2.split(cv2.cvtColor(masked, cv2.COLOR_BGR2LAB))
    l = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8)).apply(l)
    enhanced = cv2.cvtColor(cv2.merge((l, a, b)), cv2.COLOR_LAB2BGR)

    # Tr√≠ch xu·∫•t Vector
    pil_img = Image.fromarray(cv2.cvtColor(enhanced, cv2.COLOR_BGR2RGB))
    tensor = arc_transform(pil_img).unsqueeze(0).to(DEVICE)
    with torch.no_grad():
        embedding = F.normalize(arcface(tensor), p=2, dim=1)

    return embedding, max_area / roi_area, "OK", enhanced


# --- 4. GIAO DI·ªÜN CH√çNH ---
st.set_page_config(page_title="Iris Guard v4", page_icon="üõ°Ô∏è")
st.title("üõ°Ô∏è H·ªá th·ªëng Nh·∫≠n di·ªán M·ªëng m·∫Øt")

# Menu b√™n tr√°i
menu = ["Ch·∫•m c√¥ng (X√°c th·ª±c)", "ƒêƒÉng k√Ω m·ªõi"]
choice = st.sidebar.selectbox("Ch·ª©c nƒÉng", menu)
st.sidebar.info("H·∫°n ch√≥t ƒë·ªì √°n: 03/01/2026")

# Kh·ªüi t·∫°o model 1 l·∫ßn
unet, arcface = init_system()

# --- M√ÄN H√åNH ƒêƒÇNG K√ù ---
if choice == "ƒêƒÉng k√Ω m·ªõi":
    st.header("üìù ƒêƒÉng k√Ω nh√¢n vi√™n m·ªõi")
    st.write("H√£y nh·∫≠p t√™n v√† ch·ª•p ·∫£nh ƒë·ªÉ t·∫°o d·ªØ li·ªáu m·∫´u.")

    new_name = st.text_input("Nh·∫≠p t√™n nh√¢n vi√™n (Kh√¥ng d·∫•u, VD: Anh, Long):")

    # Ch·ª•p ·∫£nh ƒëƒÉng k√Ω
    reg_img = st.camera_input("Ch·ª•p ·∫£nh m·∫´u (N√™n ch·ª•p 2-3 l·∫ßn ·ªü c√°c g√≥c s√°ng kh√°c nhau)")

    if reg_img and new_name:
        bytes_data = np.asarray(bytearray(reg_img.read()), dtype=np.uint8)
        frame = cv2.imdecode(bytes_data, 1)

        with st.spinner("ƒêang tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng..."):
            emb, ratio, status, enhanced_img = extract_v4(frame, unet, arcface)

        if emb is None:
            st.error(f"Kh√¥ng th·ªÉ l·∫•y m·∫´u: {status}. Vui l√≤ng ch·ª•p l·∫°i!")
            st.image(frame, caption="·∫¢nh l·ªói", width=300)
        else:
            col1, col2 = st.columns(2)
            with col1:
                st.image(enhanced_img, caption="M·ªëng m·∫Øt tr√≠ch xu·∫•t", channels="BGR")
            with col2:
                st.success("Tr√≠ch xu·∫•t th√†nh c√¥ng!")
                if st.button("L∆∞u d·ªØ li·ªáu n√†y"):
                    save_embedding(new_name, emb)
                    st.toast(f"ƒê√£ l∆∞u d·ªØ li·ªáu cho: {new_name}!", icon="‚úÖ")
                    st.info("M·∫πo: B·∫°n c√≥ th·ªÉ ch·ª•p ti·∫øp t·∫•m n·ªØa v√† b·∫•m L∆∞u ƒë·ªÉ l√†m d·ªØ li·ªáu phong ph√∫ h∆°n.")

# --- M√ÄN H√åNH CH·∫§M C√îNG ---
elif choice == "Ch·∫•m c√¥ng (X√°c th·ª±c)":
    st.header("clock in/out")

    # Load l·∫°i DB m·ªói l·∫ßn v√†o m√†n h√¨nh n√†y ƒë·ªÉ c·∫≠p nh·∫≠t ng∆∞·ªùi m·ªõi
    identity_db = load_identity_db()

    if not identity_db:
        st.warning("Ch∆∞a c√≥ d·ªØ li·ªáu nh√¢n vi√™n. Vui l√≤ng sang tab 'ƒêƒÉng k√Ω m·ªõi' ƒë·ªÉ t·∫°o d·ªØ li·ªáu.")
    else:
        st.success(f"H·ªá th·ªëng ƒë√£ s·∫µn s√†ng v·ªõi {len(identity_db)} nh√¢n vi√™n: {', '.join(identity_db.keys())}")

        check_img = st.camera_input("Qu√©t m·ªëng m·∫Øt ƒë·ªÉ ch·∫•m c√¥ng")

        if check_img:
            bytes_data = np.asarray(bytearray(check_img.read()), dtype=np.uint8)
            frame = cv2.imdecode(bytes_data, 1)

            emb, ratio, status, enhanced_img = extract_v4(frame, unet, arcface)

            if emb is None:
                st.warning(f"L·ªói: {status}")
            else:
                # --- LOGIC SO KH·ªöP 1-N ---
                best_score = -1.0
                best_name = "Unknown"

                for name, ref_emb in identity_db.items():
                    score = torch.mm(emb, ref_emb.t()).item()
                    if score > best_score:
                        best_score = score
                        best_name = name

                # Hi·ªÉn th·ªã
                col1, col2 = st.columns(2)
                with col1:
                    st.image(frame, caption="·∫¢nh qu√©t", channels="BGR")
                with col2:
                    st.image(enhanced_img, caption="M·ªëng m·∫Øt", channels="BGR")

                st.divider()

                if best_score > THRESHOLD:
                    st.success(f"‚úÖ X√ÅC TH·ª∞C TH√ÄNH C√îNG: {best_name.upper()}")
                    st.metric(label="ƒê·ªô tin c·∫≠y", value=f"{best_score:.4f}", delta="H·ª£p l·ªá")
                    st.balloons()
                else:
                    st.error("‚ùå T·ª™ CH·ªêI TRUY C·∫¨P")
                    st.write(f"Ng∆∞·ªùi gi·ªëng nh·∫•t: {best_name} ({best_score:.4f}) - D∆∞·ªõi ng∆∞·ª°ng {THRESHOLD}")